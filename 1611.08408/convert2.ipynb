{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeplab (\n",
      "  (features): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU ()\n",
      "    (4): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU ()\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU ()\n",
      "    (9): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU ()\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU ()\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU ()\n",
      "    (16): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU ()\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU ()\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU ()\n",
      "    (23): MaxPool2d (size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (25): ReLU ()\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (27): ReLU ()\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
      "    (29): ReLU ()\n",
      "    (30): MaxPool2d (size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (fc1): Sequential (\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (1): ReLU ()\n",
      "    (2): Dropout (p = 0.5)\n",
      "    (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU ()\n",
      "    (5): Dropout (p = 0.5)\n",
      "  )\n",
      "  (classifiers1): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc2): Sequential (\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
      "    (1): ReLU ()\n",
      "    (2): Dropout (p = 0.5)\n",
      "    (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU ()\n",
      "    (5): Dropout (p = 0.5)\n",
      "  )\n",
      "  (classifiers2): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc3): Sequential (\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
      "    (1): ReLU ()\n",
      "    (2): Dropout (p = 0.5)\n",
      "    (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU ()\n",
      "    (5): Dropout (p = 0.5)\n",
      "  )\n",
      "  (fc4): Sequential (\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
      "    (1): ReLU ()\n",
      "    (2): Dropout (p = 0.5)\n",
      "    (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU ()\n",
      "    (5): Dropout (p = 0.5)\n",
      "  )\n",
      "  (classifiers4): Conv2d(1024, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ") ['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'fc1.0.weight', 'fc1.0.bias', 'fc1.3.weight', 'fc1.3.bias', 'classifiers1.weight', 'classifiers1.bias', 'fc2.0.weight', 'fc2.0.bias', 'fc2.3.weight', 'fc2.3.bias', 'classifiers2.weight', 'classifiers2.bias', 'fc3.0.weight', 'fc3.0.bias', 'fc3.3.weight', 'fc3.3.bias', 'fc4.0.weight', 'fc4.0.bias', 'fc4.3.weight', 'fc4.3.bias', 'classifiers4.weight', 'classifiers4.bias']\n",
      "in features.0.weight\n",
      "in features.0.bias\n",
      "in features.2.weight\n",
      "in features.2.bias\n",
      "in features.5.weight\n",
      "in features.5.bias\n",
      "in features.7.weight\n",
      "in features.7.bias\n",
      "in features.10.weight\n",
      "in features.10.bias\n",
      "in features.12.weight\n",
      "in features.12.bias\n",
      "in features.14.weight\n",
      "in features.14.bias\n",
      "in features.17.weight\n",
      "in features.17.bias\n",
      "in features.19.weight\n",
      "in features.19.bias\n",
      "in features.21.weight\n",
      "in features.21.bias\n",
      "in features.24.weight\n",
      "in features.24.bias\n",
      "in features.26.weight\n",
      "in features.26.bias\n",
      "in features.28.weight\n",
      "in features.28.bias\n",
      "out fc1.0.weight classifier.0.weight\n",
      "out fc1.0.bias classifier.0.bias\n",
      "out fc1.3.weight classifier.3.weight\n",
      "out fc1.3.bias classifier.3.bias\n",
      "out fc2.0.weight classifier.0.weight\n",
      "out fc2.0.bias classifier.0.bias\n",
      "out fc2.3.weight classifier.3.weight\n",
      "out fc2.3.bias classifier.3.bias\n",
      "out fc3.0.weight classifier.0.weight\n",
      "out fc3.0.bias classifier.0.bias\n",
      "out fc3.3.weight classifier.3.weight\n",
      "out fc3.3.bias classifier.3.bias\n",
      "out fc4.0.weight classifier.0.weight\n",
      "out fc4.0.bias classifier.0.bias\n",
      "out fc4.3.weight classifier.3.weight\n",
      "out fc4.3.bias classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "import torch.nn.functional as f\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "max_step = 20000\n",
    "\n",
    "class Deeplab(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Deeplab, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        '''\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv1_1', nn.Conv2d(3, 64, kernel_size=3, padding=1)),\n",
    "            ('relu1_1', nn.ReLU(False)),\n",
    "            ('conv1_2', nn.Conv2d(64, 64, kernel_size=3, padding=1)),\n",
    "            ('relu1_2', nn.ReLU(False)),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "\n",
    "            ('conv2_1', nn.Conv2d(64, 128, kernel_size=3, padding=1)),\n",
    "            ('relu2_1', nn.ReLU(False)),\n",
    "            ('conv2_2', nn.Conv2d(128, 128, kernel_size=3, padding=1)),\n",
    "            ('relu2_2', nn.ReLU(False)),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "\n",
    "            ('conv3_1', nn.Conv2d(128, 256, kernel_size=3, padding=1)),\n",
    "            ('relu3_1', nn.ReLU(False)),\n",
    "            ('conv3_2', nn.Conv2d(256, 256, kernel_size=3, padding=1)),\n",
    "            ('relu3_2', nn.ReLU(False)),\n",
    "            ('conv3_3', nn.Conv2d(256, 256, kernel_size=3, padding=1)),\n",
    "            ('relu3_3', nn.ReLU(False)),\n",
    "            ('pool3', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "\n",
    "            ('conv4_1', nn.Conv2d(256, 512, kernel_size=3, padding=1)),\n",
    "            ('relu4_1', nn.ReLU(False)),\n",
    "            ('conv4_2', nn.Conv2d(512, 512, kernel_size=3, padding=1)),\n",
    "            ('relu4_2', nn.ReLU(False)),\n",
    "            ('conv4_3', nn.Conv2d(512, 512, kernel_size=3, padding=1)),\n",
    "            ('relu4_3', nn.ReLU(False)),\n",
    "            ('pool4', nn.MaxPool2d(kernel_size=3, stride=1, padding=1)),\n",
    "\n",
    "            ('conv5_1', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2)),\n",
    "            ('relu5_1', nn.ReLU(False)),\n",
    "            ('conv5_2', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2)),\n",
    "            ('relu5_2', nn.ReLU(False)),\n",
    "            ('conv5_3', nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2)),\n",
    "            ('relu5_3', nn.ReLU(False)),\n",
    "            ('pool5', nn.MaxPool2d(kernel_size=3, stride=1, padding=1)),\n",
    "            ])\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Sequential(OrderedDict(\n",
    "            [('fc6_1', nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)),\n",
    "             ('relu6_1', nn.ReLU(False)),\n",
    "             ('dropout6_1', nn.Dropout(0.5, False)),\n",
    "\n",
    "             ('fc7_1', nn.Conv2d(1024, 1024, kernel_size=1)),\n",
    "             ('relu7_1', nn.ReLU(False)),\n",
    "             ('dropout7_1', nn.Dropout(0.5, False)),\n",
    "             ])\n",
    "        )\n",
    "\n",
    "        self.classifiers1 = nn.Sequential(OrderedDict(\n",
    "            [('fc8_cxr_2', nn.Conv2d(1024, self.n_classes, kernel_size=1)),])\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(OrderedDict(\n",
    "            [('fc6_2', nn.Conv2d(512, 1024, kernel_size=3, padding=12, dilation=12)),\n",
    "             ('relu6_2', nn.ReLU(False)),\n",
    "             ('dropout6_2', nn.Dropout(0.5, False)),\n",
    "\n",
    "             ('fc7_2', nn.Conv2d(1024, 1024, kernel_size=1)),\n",
    "             ('relu7_2', nn.ReLU(False)),\n",
    "             ('dropout7_2', nn.Dropout(0.5, False)),\n",
    "             ])\n",
    "        )\n",
    "\n",
    "        self.classifiers2 = nn.Sequential(OrderedDict(\n",
    "            [('fc8_cxr_2', nn.Conv2d(1024, self.n_classes, kernel_size=1)),])\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Sequential(OrderedDict(\n",
    "            [('fc6_3', nn.Conv2d(512, 1024, kernel_size=3, padding=16, dilation=16)),\n",
    "             ('relu6_3', nn.ReLU(False)),\n",
    "             ('dropout6_3', nn.Dropout(0.5, False)),\n",
    "\n",
    "             ('fc7_3', nn.Conv2d(1024, 1024, kernel_size=1)),\n",
    "             ('relu7_3', nn.ReLU(False)),\n",
    "             ('dropout7_3', nn.Dropout(0.5, False)),\n",
    "             ])\n",
    "        )\n",
    "\n",
    "        self.classifiers3 = nn.Sequential(OrderedDict(\n",
    "            [('fc8_cxr_3', nn.Conv2d(1024, self.n_classes, kernel_size=1)),])\n",
    "        )\n",
    "\n",
    "        self.fc4 = nn.Sequential(OrderedDict(\n",
    "            [('fc6_4', nn.Conv2d(512, 1024, kernel_size=3, padding=24, dilation=24)),\n",
    "             ('relu6_4', nn.ReLU(False)),\n",
    "             ('dropout6_4', nn.Dropout(0.5, False)),\n",
    "\n",
    "             ('fc7_4', nn.Conv2d(1024, 1024, kernel_size=1)),\n",
    "             ('relu7_4', nn.ReLU(False)),\n",
    "             ('dropout7_4', nn.Dropout(0.5, False)),\n",
    "             ])\n",
    "        )\n",
    "\n",
    "        self.classifiers4 = nn.Sequential(OrderedDict(\n",
    "            [('fc8_cxr_4', nn.Conv2d(1024, self.n_classes, kernel_size=1)),])\n",
    "        )\n",
    "        '''\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.ReLU(False),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.ReLU(False),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "        )\n",
    "\n",
    "        self.classifiers1 = nn.Conv2d(1024, self.n_classes, kernel_size=1)\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=12, dilation=12),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "        )\n",
    "        self.classifiers2 = nn.Conv2d(1024, self.n_classes, kernel_size=1)\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=18, dilation=18),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "        )\n",
    "        self.classifiers3 = nn.Conv2d(1024, self.n_classes, kernel_size=1),\n",
    "\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=24, dilation=24),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "            nn.ReLU(False),\n",
    "            nn.Dropout(0.5, False),\n",
    "        )\n",
    "        self.classifiers4 = nn.Conv2d(1024, self.n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.features(inputs)\n",
    "        fc1 = self.fc1(features)\n",
    "        fc2 = self.fc2(features)\n",
    "        fc3 = self.fc3(features)\n",
    "        fc4 = self.fc4(features)\n",
    "        outputs = self.classifiers1(fc1) + self.classifiers2(fc2) \\\n",
    "                + self.classifiers3(fc3) + self.classifiers4(fc4)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, decay_rate=0.9, step=0):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * ((1 - 1.0*step/max_step)**decay_rate)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # nn.init.xavier_normal(m.weight.data)\n",
    "        # nn.init.constant(m.bias.data, 0)\n",
    "        nn.init.normal(m.weight.data, mean=0, std=0.01)\n",
    "        nn.init.constant(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    preds = preds.data.cpu().numpy()\n",
    "    targets = targets.data.cpu().numpy()\n",
    "    batch = preds.shape[0]\n",
    "\n",
    "    results = 0\n",
    "    for i in xrange(batch):\n",
    "        pred = np.array(preds[i,:,:,:])\n",
    "        target = np.array(targets[i,:,:])\n",
    "        pred = np.argmax(pred, axis=0)\n",
    "\n",
    "        print pred\n",
    "\n",
    "        results += (pred == target).sum()\n",
    "\n",
    "    return results*1.0/batch/preds.shape[1]/preds.shape[2]\n",
    "\n",
    "model = Deeplab(2)\n",
    "model.apply(weights_init)\n",
    "model_dict = model.state_dict()\n",
    "keys = model_dict.keys()\n",
    "print model, keys\n",
    "\n",
    "pretrained_dict = torchvision.models.vgg16(pretrained=True).state_dict()\n",
    "\n",
    "for k in model_dict:\n",
    "    if k in pretrained_dict:\n",
    "        model_dict[k] = pretrained_dict[k]\n",
    "        print 'in', k\n",
    "    else:\n",
    "        if 'fc' in k:\n",
    "            prek = 'classifier' + k[3:]\n",
    "            print 'out', k, prek\n",
    "            model_dict[k] = pretrained_dict[prek]\n",
    "\n",
    "torch.save(model_dict, 'init.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
