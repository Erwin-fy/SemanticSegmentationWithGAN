{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1', 'conv3_2', 'conv3_3', 'conv4_1', 'conv4_2', 'conv4_3', 'conv5_1', 'conv5_2', 'conv5_3', 'fc6_1', 'fc7_1', 'fc8_carvana_1', 'fc6_2', 'fc7_2', 'fc8_carvana_2', 'fc6_3', 'fc7_3', 'fc8_carvana_3', 'fc6_4', 'fc7_4', 'fc8_carvana_4']\n",
      "0 features.conv1_1.weight features.conv1_1.weight conv1_1\n",
      "1 features.conv1_1.bias features.conv1_1.bias conv1_1\n",
      "2 features.conv1_2.weight features.conv1_2.weight conv1_2\n",
      "3 features.conv1_2.bias features.conv1_2.bias conv1_2\n",
      "4 features.conv2_1.weight features.conv2_1.weight conv2_1\n",
      "5 features.conv2_1.bias features.conv2_1.bias conv2_1\n",
      "6 features.conv2_2.weight features.conv2_2.weight conv2_2\n",
      "7 features.conv2_2.bias features.conv2_2.bias conv2_2\n",
      "8 features.conv3_1.weight features.conv3_1.weight conv3_1\n",
      "9 features.conv3_1.bias features.conv3_1.bias conv3_1\n",
      "10 features.conv3_2.weight features.conv3_2.weight conv3_2\n",
      "11 features.conv3_2.bias features.conv3_2.bias conv3_2\n",
      "12 features.conv3_3.weight features.conv3_3.weight conv3_3\n",
      "13 features.conv3_3.bias features.conv3_3.bias conv3_3\n",
      "14 features.conv4_1.weight features.conv4_1.weight conv4_1\n",
      "15 features.conv4_1.bias features.conv4_1.bias conv4_1\n",
      "16 features.conv4_2.weight features.conv4_2.weight conv4_2\n",
      "17 features.conv4_2.bias features.conv4_2.bias conv4_2\n",
      "18 features.conv4_3.weight features.conv4_3.weight conv4_3\n",
      "19 features.conv4_3.bias features.conv4_3.bias conv4_3\n",
      "20 features.conv5_1.weight features.conv5_1.weight conv5_1\n",
      "21 features.conv5_1.bias features.conv5_1.bias conv5_1\n",
      "22 features.conv5_2.weight features.conv5_2.weight conv5_2\n",
      "23 features.conv5_2.bias features.conv5_2.bias conv5_2\n",
      "24 features.conv5_3.weight features.conv5_3.weight conv5_3\n",
      "25 features.conv5_3.bias features.conv5_3.bias conv5_3\n",
      "26 classifiers1.fc6_1.weight classifiers1.fc6_1.weight fc6_1\n",
      "27 classifiers1.fc6_1.bias classifiers1.fc6_1.bias fc6_1\n",
      "28 classifiers1.fc7_1.weight classifiers1.fc7_1.weight fc7_1\n",
      "29 classifiers1.fc7_1.bias classifiers1.fc7_1.bias fc7_1\n",
      "30 classifiers1.fc8_voc12_1.weight classifiers1.fc8_voc12_1.weight fc8_carvana_1\n",
      "31 classifiers1.fc8_voc12_1.bias classifiers1.fc8_voc12_1.bias fc8_carvana_1\n",
      "32 classifiers2.fc6_2.weight classifiers2.fc6_2.weight fc6_2\n",
      "33 classifiers2.fc6_2.bias classifiers2.fc6_2.bias fc6_2\n",
      "34 classifiers2.fc7_2.weight classifiers2.fc7_2.weight fc7_2\n",
      "35 classifiers2.fc7_2.bias classifiers2.fc7_2.bias fc7_2\n",
      "36 classifiers2.fc8_voc12_2.weight classifiers2.fc8_voc12_2.weight fc8_carvana_2\n",
      "37 classifiers2.fc8_voc12_2.bias classifiers2.fc8_voc12_2.bias fc8_carvana_2\n",
      "38 classifiers3.fc6_3.weight classifiers3.fc6_3.weight fc6_3\n",
      "39 classifiers3.fc6_3.bias classifiers3.fc6_3.bias fc6_3\n",
      "40 classifiers3.fc7_3.weight classifiers3.fc7_3.weight fc7_3\n",
      "41 classifiers3.fc7_3.bias classifiers3.fc7_3.bias fc7_3\n",
      "42 classifiers3.fc8_voc12_3.weight classifiers3.fc8_voc12_3.weight fc8_carvana_3\n",
      "43 classifiers3.fc8_voc12_3.bias classifiers3.fc8_voc12_3.bias fc8_carvana_3\n",
      "44 classifiers4.fc6_4.weight classifiers4.fc6_4.weight fc6_4\n",
      "45 classifiers4.fc6_4.bias classifiers4.fc6_4.bias fc6_4\n",
      "46 classifiers4.fc7_4.weight classifiers4.fc7_4.weight fc7_4\n",
      "47 classifiers4.fc7_4.bias classifiers4.fc7_4.bias fc7_4\n",
      "48 classifiers4.fc8_voc12_4.weight classifiers4.fc8_voc12_4.weight fc8_carvana_4\n",
      "49 classifiers4.fc8_voc12_4.bias classifiers4.fc8_voc12_4.bias fc8_carvana_4\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import caffe\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "caffe.set_mode_cpu\n",
    "net0 = caffe.Net('/home/liguanbin/wangfuyu/deeplab-public-ver2/exper/carvana/config/VGG_16/train_weight.prototxt',\\\n",
    "                 '/home/liguanbin/deeplab-public-ver2/exper/cxr/model/deeplab_vgg16/init.caffemodel',caffe.TEST)\n",
    "\n",
    "caffekeys = net0.params.keys()   \n",
    "    \n",
    "\n",
    "\n",
    "print caffekeys\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "torchkeys = ['features.conv1_1.weight', 'features.conv1_1.bias', 'features.conv1_2.weight', 'features.conv1_2.bias', 'features.conv2_1.weight', 'features.conv2_1.bias', 'features.conv2_2.weight', 'features.conv2_2.bias', 'features.conv3_1.weight', 'features.conv3_1.bias', 'features.conv3_2.weight', 'features.conv3_2.bias', 'features.conv3_3.weight', 'features.conv3_3.bias', 'features.conv4_1.weight', 'features.conv4_1.bias', 'features.conv4_2.weight', 'features.conv4_2.bias', 'features.conv4_3.weight', 'features.conv4_3.bias', 'features.conv5_1.weight', 'features.conv5_1.bias', 'features.conv5_2.weight', 'features.conv5_2.bias', 'features.conv5_3.weight', 'features.conv5_3.bias', 'classifiers1.fc6_1.weight', 'classifiers1.fc6_1.bias', 'classifiers1.fc7_1.weight', 'classifiers1.fc7_1.bias', 'classifiers1.fc8_voc12_1.weight', 'classifiers1.fc8_voc12_1.bias', 'classifiers2.fc6_2.weight', 'classifiers2.fc6_2.bias', 'classifiers2.fc7_2.weight', 'classifiers2.fc7_2.bias', 'classifiers2.fc8_voc12_2.weight', 'classifiers2.fc8_voc12_2.bias', 'classifiers3.fc6_3.weight', 'classifiers3.fc6_3.bias', 'classifiers3.fc7_3.weight', 'classifiers3.fc7_3.bias', 'classifiers3.fc8_voc12_3.weight', 'classifiers3.fc8_voc12_3.bias', 'classifiers4.fc6_4.weight', 'classifiers4.fc6_4.bias', 'classifiers4.fc7_4.weight', 'classifiers4.fc7_4.bias', 'classifiers4.fc8_voc12_4.weight', 'classifiers4.fc8_voc12_4.bias']\n",
    "\n",
    "for index, key in enumerate(torchkeys):\n",
    "    new_state_dict[torchkeys[index]] = np.copy(net0.params[caffekeys[int(index/2)]][index%2].data[:])\n",
    "    print index, key, torchkeys[index],caffekeys[int(index/2)]\n",
    "\n",
    "print len(caffekeys)    \n",
    "\n",
    "# Save\n",
    "np.save('voc12.npy', new_state_dict) \n",
    "\n",
    "# # Load\n",
    "# read_dictionary = np.load('my_file.npy').item()\n",
    "# print(read_dictionary['hello']) # displays \"world\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
